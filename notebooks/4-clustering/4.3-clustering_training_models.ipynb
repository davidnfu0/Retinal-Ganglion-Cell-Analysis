{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Training Models: Ganglion Cells in the Retina\n",
    "\n",
    "- **Author**: David Felipe\n",
    "- **Contact**: https://github.com/davidnfu0\n",
    "- **Last Modification**: January 30, 2024\n",
    "- **Description:** In this document, we will train models according to the hyperparameters identified previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans, DBSCAN, HDBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import load_yaml_config, hide_warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the configuration\n",
    "configPath = \"../../config/\"\n",
    "config = load_yaml_config(configPath + \"general_config.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"../../\" + config[\"paths\"][\"data_cache\"][\"clustering\"][\"DFS_NORM\"], \"rb\"\n",
    ") as file:\n",
    "    dfs_norm = pickle.load(file)\n",
    "with open(\n",
    "    \"../../\" + config[\"paths\"][\"data_cache\"][\"clustering\"][\"PARAMS\"], \"rb\"\n",
    ") as file:\n",
    "    clustering_params = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_warnings()\n",
    "k_means = dict()\n",
    "k_means_pred = dict()\n",
    "k_means_centroids = dict()\n",
    "\n",
    "for df_name, data in dfs_norm.items():\n",
    "    k_means[df_name] = KMeans(**(clustering_params[\"k-means\"][df_name])).fit(data)\n",
    "    k_means_pred[df_name] = k_means[df_name].labels_\n",
    "    k_means_centroids[df_name] = k_means[df_name].cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscans = dict()\n",
    "dbscans_pred = dict()\n",
    "\n",
    "for df_name, data in dfs_norm.items():\n",
    "    dbscans[df_name] = DBSCAN(**clustering_params[\"dbscan\"][df_name]).fit(data)\n",
    "    dbscans_pred[df_name] = dbscans[df_name].labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmms = dict()\n",
    "gmms_pred = dict()\n",
    "\n",
    "for df_name, data in dfs_norm.items():\n",
    "    gmms[df_name] = GaussianMixture(**clustering_params[\"gmm\"][df_name]).fit(data)\n",
    "    gmms_pred[df_name] = gmms[df_name].predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscans = dict()\n",
    "hdbscans_pred = dict()\n",
    "\n",
    "for df_name, data in dfs_norm.items():\n",
    "    hdbscans[df_name] = HDBSCAN(**clustering_params[\"hdbscan\"][df_name]).fit(data)\n",
    "    hdbscans_pred[df_name] = hdbscans[df_name].labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomeratives = dict()\n",
    "agglomeratives_pred = dict()\n",
    "\n",
    "for df_name, data in dfs_norm.items():\n",
    "    agglomeratives[df_name] = AgglomerativeClustering(\n",
    "        **clustering_params[\"agglomerative\"][df_name]\n",
    "    ).fit(data)\n",
    "    agglomeratives_pred[df_name] = agglomeratives[df_name].labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_models = dict()\n",
    "clustering_models[\"k-means\"] = k_means\n",
    "clustering_models[\"dbscan\"] = dbscans\n",
    "clustering_models[\"gmm\"] = gmms\n",
    "clustering_models[\"hdbscan\"] = hdbscans\n",
    "clustering_models[\"agglomerative\"] = agglomeratives\n",
    "\n",
    "\n",
    "clustering_pred = dict()\n",
    "clustering_pred[\"k-means\"] = k_means_pred\n",
    "clustering_pred[\"dbscan\"] = dbscans_pred\n",
    "clustering_pred[\"gmm\"] = gmms_pred\n",
    "clustering_pred[\"hdbscan\"] = hdbscans_pred\n",
    "clustering_pred[\"agglomerative\"] = agglomeratives_pred\n",
    "\n",
    "clustering_centroids = dict()\n",
    "clustering_centroids[\"k-means\"] = k_means_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"../../\" + config[\"paths\"][\"data_cache\"][\"clustering\"][\"MODELS\"], \"wb\"\n",
    ") as output:\n",
    "    pickle.dump(clustering_models, output)\n",
    "\n",
    "with open(\n",
    "    \"../../\" + config[\"paths\"][\"data_cache\"][\"clustering\"][\"PREDS\"], \"wb\"\n",
    ") as output:\n",
    "    pickle.dump(clustering_pred, output)\n",
    "\n",
    "with open(\n",
    "    \"../../\" + config[\"paths\"][\"data_cache\"][\"clustering\"][\"CENTROIDS\"], \"wb\"\n",
    ") as output:\n",
    "    pickle.dump(clustering_centroids, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ganglion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
